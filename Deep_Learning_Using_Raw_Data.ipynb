{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip The Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.11.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /home/erklarungsnot/miniconda3/lib/python3.10/site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: keras-tuner, tflite-model-maker\n"
     ]
    }
   ],
   "source": [
    "!./unzip.sh UCI_HAR_Dataset.zip 2>&1 > /dev/null\n",
    "!pip install -q --no-dependencies tflite-model-maker\n",
    "!pip install -q tensorflow==2.11.0\n",
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 18:30:29.523567: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-08 18:30:29.765605: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-08 18:30:29.765628: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-08 18:30:30.763659: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-08 18:30:30.763719: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-08 18:30:30.763725: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "# tf.enable_control_flow_v2() # only for tf 1.0\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import LSTM, BatchNormalization, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", message=\"calling BaseResourceVariable.__init__.*constraint is deprecated\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(targets, nb_classes):\n",
    "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "    return res.reshape(list(targets.shape) + [nb_classes])\n",
    "\n",
    "\n",
    "def load_y(subset):\n",
    "    # Get the path\n",
    "    path = f\"UCI_HAR_Dataset/UCI_HAR_Dataset/{subset}/y_{subset}.txt\"\n",
    "\n",
    "    # Read the file\n",
    "    y = np.loadtxt(path, delimiter=\",\", dtype=int)\n",
    "\n",
    "    # # One-hot encode labels\n",
    "    one_hot_labels = get_one_hot(y - 1, len(np.unique(y)))\n",
    "    if subset == \"train\":\n",
    "        assert one_hot_labels.shape == (\n",
    "            7352,\n",
    "            6,\n",
    "        ), f\"Wrong dimensions: {one_hot_labels.shape} should be (7352, 6)\"\n",
    "    if subset == \"test\":\n",
    "        assert one_hot_labels.shape == (\n",
    "            2947,\n",
    "            6,\n",
    "        ), f\"Wrong dimensions: {one_hot_labels.shape} should be (2947, 6)\"\n",
    "    assert (\n",
    "        y[0] - 1 == np.where(one_hot_labels[0] == np.max(one_hot_labels[0]))[0][0]\n",
    "    ), f\"Value mismatch {np.max(one_hot_labels[0])[0][0]} vs {y[13] - 1}\"\n",
    "    return one_hot_labels\n",
    "\n",
    "\n",
    "def build_data(subset):\n",
    "    if subset not in [\"train\", \"val\", \"test\"]:\n",
    "        raise Exception(f\"Invalid subset: {subset}\")\n",
    "\n",
    "    folder_path = f\"UCI_HAR_Dataset/UCI_HAR_Dataset/{subset}/Inertial Signals/\"\n",
    "\n",
    "    # Get all signal files in folder\n",
    "    signal_files = glob.glob(os.path.join(folder_path, \"*.txt\"))\n",
    "    # print(signal_files)\n",
    "\n",
    "    assert len(signal_files) == 9, f\"No signal files found in {folder_path}\"\n",
    "    np.loadtxt(signal_files[0]).shape\n",
    "    # print(f\"{signal_shape}\")\n",
    "\n",
    "    # Determine signal order based on file names\n",
    "    signal_order = [\n",
    "        \"body_acc_x_\",\n",
    "        \"body_acc_y_\",\n",
    "        \"body_acc_z_\",\n",
    "        \"body_gyro_x_\",\n",
    "        \"body_gyro_y_\",\n",
    "        \"body_gyro_z_\",\n",
    "        \"total_acc_x_\",\n",
    "        \"total_acc_y_\",\n",
    "        \"total_acc_z_\",\n",
    "    ]\n",
    "\n",
    "    # file_prefix = \"UCI_HAR_Dataset/UCI_HAR_Dataset/train/Inertial Signals/\"\n",
    "    # file_suffix = \".txt\"\n",
    "    signal_files = [\n",
    "        f\"UCI_HAR_Dataset/UCI_HAR_Dataset/{subset}/Inertial Signals/{x}{subset}.txt\"\n",
    "        for x in signal_order\n",
    "    ]\n",
    "\n",
    "    # Load signal data from each file and append to signals_data list\n",
    "    signals_data = [np.loadtxt(x) for x in signal_files]\n",
    "\n",
    "    # Transpose signal data array so that shape is (number of samples, number of timesteps, number of signals)\n",
    "    signals_data = np.transpose(signals_data, (1, 2, 0))\n",
    "\n",
    "    # Verify final shape of combined data\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    if subset == \"train\":\n",
    "        assert signals_data.shape == (7352, 128, len(signal_files))\n",
    "    else:\n",
    "        assert signals_data.shape == (2947, 128, len(signal_files))\n",
    "    return signals_data\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    return build_data(\"train\"), load_y(\"train\"), build_data(\"test\"), load_y(\"test\")\n",
    "\n",
    "\n",
    "# Loading the train and test data\n",
    "X_train, y_train, X_test, y_test = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sample = X_train[0]\n",
    "first_timestep = first_sample[0]\n",
    "assert len(first_sample) == 128\n",
    "assert first_timestep[0] == 1.8085150e-004, print(first_timestep[0])\n",
    "assert first_timestep[1] == 1.0766810e-002, print(first_timestep[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "assert X_train.shape == (7352, 128, 9), print(\n",
    "    \"Expected shape: (7352, 128, 9) get\", X_train.shape\n",
    ")\n",
    "assert X_test.shape == (2947, 128, 9), print(\n",
    "    \"Expected: (2947, 128, 9) get\", X_test.shape\n",
    ")\n",
    "assert y_train.shape == (7352, 6), print(\"Expected: (7352, 6) get\", y_train.shape)\n",
    "assert y_test.shape == (2947, 6), print(\"Expected: (2947, 6) get\", y_test.shape)\n",
    "assert len(X_train[0][0]) == 9, print(\"Signals numbers not match\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Create the \"assets\" folder if it does not exist\n",
    "if not os.path.exists(\"assets\"):\n",
    "    os.mkdir(\"assets\")\n",
    "\n",
    "# Create the \"assets/data\" folder if it does not exist\n",
    "data_folder = os.path.join(\"assets\", \"data\")\n",
    "if not os.path.exists(data_folder):\n",
    "    os.mkdir(data_folder)\n",
    "\n",
    "\n",
    "def save_data_to_pickle_shards(data, data_name, data_folder):\n",
    "    # Check if the data already exists\n",
    "    filename = os.path.join(data_folder, f\"{data_name}_0.pickle\")\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"{data_name} already exists in {data_folder}. Skipping data saving.\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(os.path.join(data_folder)):\n",
    "        os.makedirs(os.path.join(data_folder))\n",
    "\n",
    "    # Serialize your data\n",
    "    serialized_data = pickle.dumps(data)\n",
    "\n",
    "    # Split the serialized data into smaller chunks\n",
    "    chunk_size = 50 * 1024 * 1024  # 50 megabytes\n",
    "    chunks = [\n",
    "        serialized_data[i : i + chunk_size]\n",
    "        for i in range(0, len(serialized_data), chunk_size)\n",
    "    ]\n",
    "\n",
    "    # Save each chunk to a file in the \"asset/data\" folder\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        filename = os.path.join(data_folder, f\"{data_name}_{i}.pickle\")\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train already exists in assets/data. Skipping data saving.\n",
      "y_train already exists in assets/data. Skipping data saving.\n",
      "X_test already exists in assets/data. Skipping data saving.\n",
      "y_test already exists in assets/data. Skipping data saving.\n"
     ]
    }
   ],
   "source": [
    "save_data_to_pickle_shards(X_train, \"X_train\", data_folder)\n",
    "save_data_to_pickle_shards(y_train, \"y_train\", data_folder)\n",
    "save_data_to_pickle_shards(X_test, \"X_test\", data_folder)\n",
    "save_data_to_pickle_shards(y_test, \"y_test\", data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "def load_data_from_pickle_shards(data_name, data_folder):\n",
    "    # Find all pickle files that match the data name\n",
    "    files = sorted(\n",
    "        [\n",
    "            os.path.join(data_folder, f)\n",
    "            for f in os.listdir(data_folder)\n",
    "            if f.startswith(data_name)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Load the data from each file\n",
    "    data = b\"\"\n",
    "    for filename in files:\n",
    "        with open(filename, \"rb\") as f:\n",
    "            data += f.read()\n",
    "\n",
    "    # Deserialize the data\n",
    "    return pickle.loads(data)\n",
    "\n",
    "\n",
    "# Load the data from the pickle shards\n",
    "loaded_X_train = load_data_from_pickle_shards(\"X_train\", data_folder)\n",
    "loaded_y_train = load_data_from_pickle_shards(\"y_train\", data_folder)\n",
    "loaded_X_test = load_data_from_pickle_shards(\"X_test\", data_folder)\n",
    "loaded_y_test = load_data_from_pickle_shards(\"y_test\", data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the loaded data matches the original data\n",
    "assert loaded_X_train.shape == X_train.shape\n",
    "assert loaded_y_train.shape == y_train.shape\n",
    "assert loaded_X_test.shape == X_test.shape\n",
    "assert loaded_y_test.shape == y_test.shape\n",
    "\n",
    "assert (loaded_X_train == X_train).all()\n",
    "assert (loaded_y_train == y_train).all()\n",
    "assert (loaded_X_test == X_test).all()\n",
    "assert (loaded_y_test == y_test).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps: 128\n",
      "Input dimention: 9\n",
      "Total samples: 7352\n"
     ]
    }
   ],
   "source": [
    "# function to count the number of classes\n",
    "def count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))\n",
    "\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = count_classes(y_train)\n",
    "\n",
    "# Initializing parameters\n",
    "n_epochs = 30\n",
    "n_batch = 16\n",
    "\n",
    "# Bias regularizer value - we will use elasticnet\n",
    "regularizer = L1L2(0.01, 0.01)\n",
    "\n",
    "print(f\"Timesteps: {timesteps}\")\n",
    "print(f\"Input dimention: {input_dim}\")\n",
    "print(f\"Total samples: {len(X_train)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 18:30:34.793912: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-08 18:30:34.793987: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-08 18:30:34.794022: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-08 18:30:34.794076: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-08 18:30:34.921342: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-08 18:30:34.922180: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128, 64)           18944     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128, 64)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 48)                21696     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 48)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 294       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,190\n",
      "Trainable params: 41,062\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model execution\n",
    "model = Sequential([\n",
    "    LSTM(\n",
    "        units=64,\n",
    "        input_shape=(timesteps, input_dim),\n",
    "        return_sequences=True,\n",
    "        bias_regularizer=regularizer,\n",
    "    ),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.50),\n",
    "    LSTM(units=48),\n",
    "    Dropout(0.50),\n",
    "    Dense(units=n_classes, activation=\"sigmoid\"),\n",
    "])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "460/460 [==============================] - 25s 50ms/step - loss: 1.6676 - accuracy: 0.7199 - val_loss: 1.8056 - val_accuracy: 0.5806\n",
      "Epoch 2/30\n",
      "460/460 [==============================] - 22s 48ms/step - loss: 0.7064 - accuracy: 0.8999 - val_loss: 0.5148 - val_accuracy: 0.8955\n",
      "Epoch 3/30\n",
      "460/460 [==============================] - 22s 49ms/step - loss: 0.3176 - accuracy: 0.9271 - val_loss: 0.2740 - val_accuracy: 0.9091\n",
      "Epoch 4/30\n",
      "460/460 [==============================] - 23s 49ms/step - loss: 0.2100 - accuracy: 0.9283 - val_loss: 0.2886 - val_accuracy: 0.9023\n",
      "Epoch 5/30\n",
      "460/460 [==============================] - 23s 49ms/step - loss: 0.2059 - accuracy: 0.9302 - val_loss: 0.2129 - val_accuracy: 0.9209\n",
      "Epoch 6/30\n",
      "460/460 [==============================] - 23s 50ms/step - loss: 0.1988 - accuracy: 0.9305 - val_loss: 0.9239 - val_accuracy: 0.6871\n",
      "Epoch 7/30\n",
      "460/460 [==============================] - 23s 49ms/step - loss: 0.1749 - accuracy: 0.9351 - val_loss: 0.3477 - val_accuracy: 0.8924\n",
      "Epoch 8/30\n",
      "460/460 [==============================] - 23s 49ms/step - loss: 0.1579 - accuracy: 0.9388 - val_loss: 0.3153 - val_accuracy: 0.8972\n",
      "Epoch 9/30\n",
      "460/460 [==============================] - 23s 50ms/step - loss: 0.2064 - accuracy: 0.9285 - val_loss: 0.6897 - val_accuracy: 0.8079\n",
      "Epoch 10/30\n",
      "460/460 [==============================] - 23s 51ms/step - loss: 0.2020 - accuracy: 0.9285 - val_loss: 0.2681 - val_accuracy: 0.9053\n",
      "Epoch 11/30\n",
      "460/460 [==============================] - 23s 50ms/step - loss: 0.1475 - accuracy: 0.9415 - val_loss: 0.3109 - val_accuracy: 0.9046\n",
      "Epoch 12/30\n",
      "460/460 [==============================] - 23s 50ms/step - loss: 0.1368 - accuracy: 0.9465 - val_loss: 0.2402 - val_accuracy: 0.9141\n",
      "Epoch 13/30\n",
      "460/460 [==============================] - 23s 51ms/step - loss: 0.1452 - accuracy: 0.9415 - val_loss: 0.2421 - val_accuracy: 0.9203\n",
      "Epoch 14/30\n",
      "460/460 [==============================] - 23s 50ms/step - loss: 0.1598 - accuracy: 0.9388 - val_loss: 0.2328 - val_accuracy: 0.9175\n",
      "Epoch 15/30\n",
      "460/460 [==============================] - 23s 50ms/step - loss: 0.1381 - accuracy: 0.9463 - val_loss: 0.2234 - val_accuracy: 0.9247\n",
      "Epoch 16/30\n",
      "460/460 [==============================] - 23s 50ms/step - loss: 0.1412 - accuracy: 0.9453 - val_loss: 0.2461 - val_accuracy: 0.9203\n",
      "Epoch 17/30\n",
      "460/460 [==============================] - 23s 51ms/step - loss: 0.1337 - accuracy: 0.9460 - val_loss: 0.3041 - val_accuracy: 0.9220\n",
      "Epoch 18/30\n",
      "460/460 [==============================] - 24s 51ms/step - loss: 0.1433 - accuracy: 0.9455 - val_loss: 0.3210 - val_accuracy: 0.8979\n",
      "Epoch 19/30\n",
      "460/460 [==============================] - 23s 51ms/step - loss: 0.1662 - accuracy: 0.9389 - val_loss: 0.2353 - val_accuracy: 0.9237\n",
      "Epoch 20/30\n",
      "460/460 [==============================] - 23s 51ms/step - loss: 0.1541 - accuracy: 0.9423 - val_loss: 0.2074 - val_accuracy: 0.9172\n",
      "Epoch 21/30\n",
      "460/460 [==============================] - 23s 51ms/step - loss: 0.1307 - accuracy: 0.9460 - val_loss: 0.2120 - val_accuracy: 0.9281\n",
      "Epoch 22/30\n",
      "460/460 [==============================] - 23s 51ms/step - loss: 0.1381 - accuracy: 0.9455 - val_loss: 0.2190 - val_accuracy: 0.9304\n",
      "Epoch 23/30\n",
      "460/460 [==============================] - 24s 52ms/step - loss: 0.1325 - accuracy: 0.9463 - val_loss: 0.2656 - val_accuracy: 0.9206\n",
      "Epoch 24/30\n",
      "460/460 [==============================] - 24s 52ms/step - loss: 0.1291 - accuracy: 0.9506 - val_loss: 0.2818 - val_accuracy: 0.9121\n",
      "Epoch 25/30\n",
      "460/460 [==============================] - 24s 53ms/step - loss: 0.1628 - accuracy: 0.9385 - val_loss: 0.2299 - val_accuracy: 0.9108\n",
      "Epoch 26/30\n",
      "460/460 [==============================] - 24s 52ms/step - loss: 0.1410 - accuracy: 0.9449 - val_loss: 0.2255 - val_accuracy: 0.9145\n",
      "Epoch 27/30\n",
      "460/460 [==============================] - 24s 52ms/step - loss: 0.1324 - accuracy: 0.9464 - val_loss: 0.3525 - val_accuracy: 0.8870\n",
      "Epoch 28/30\n",
      "460/460 [==============================] - 24s 52ms/step - loss: 0.1447 - accuracy: 0.9453 - val_loss: 0.2208 - val_accuracy: 0.9301\n",
      "Epoch 29/30\n",
      "460/460 [==============================] - 24s 52ms/step - loss: 0.1210 - accuracy: 0.9501 - val_loss: 0.2226 - val_accuracy: 0.9250\n",
      "Epoch 30/30\n",
      "460/460 [==============================] - 27s 58ms/step - loss: 0.1352 - accuracy: 0.9470 - val_loss: 0.2475 - val_accuracy: 0.9196\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# Training the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=n_batch,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=n_epochs,\n",
    ")\n",
    "model.save(\"assets/model-backup.h5\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Rebuilt Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first half of array1 is equal to the second half of array0.\n",
      "The first half of array2 is equal to the second half of array1.\n",
      "The first half of array3 is equal to the second half of array2.\n",
      "The first half of array4 is equal to the second half of array3.\n",
      "The first half of array5 is equal to the second half of array4.\n",
      "The first half of array6 is equal to the second half of array5.\n",
      "The first half of array7 is equal to the second half of array6.\n",
      "The first half of array8 is equal to the second half of array7.\n",
      "The first half of array9 is equal to the second half of array8.\n",
      "The first half of array10 is equal to the second half of array9.\n",
      "Success threshhold passed, stopping check\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "success_thresh = 10\n",
    "passed = 0\n",
    "\n",
    "def compare_array_halves(array1, array2):\n",
    "    n = len(array1) // 2\n",
    "    return np.array_equal(array1[:n], array2[n:])\n",
    "\n",
    "\n",
    "for i in range(len(loaded_X_train)):\n",
    "    for j in range(len(loaded_X_train)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        result = compare_array_halves(loaded_X_train[i], loaded_X_train[j])\n",
    "        if result:\n",
    "            passed += 1\n",
    "            print(\n",
    "                f\"The first half of array{i} is equal to the second half of array{j}.\"\n",
    "            )\n",
    "            break\n",
    "    if passed == success_thresh:\n",
    "        print(f\"Success threshhold passed, stopping check\")\n",
    "        break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuilding Model From Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It can be used to reconstruct the model identically.\n",
    "reconstructed_model = keras.models.load_model(\"assets/model-backup.h5\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking The Rebuilt Model From Backup File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 616ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n"
     ]
    }
   ],
   "source": [
    "test_input = X_test[0].reshape((1, 128, 9))\n",
    "\n",
    "# Let's check:\n",
    "np.testing.assert_allclose(\n",
    "    model.predict(test_input), reconstructed_model.predict(test_input)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "assert np.array(model.predict(test_input)).argmax() + 1 == np.array(y_test[0]).argmax() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It can be used to reconstruct the model identically.\n",
    "reconstructed_model = keras.models.load_model(\"assets/model-backup.h5\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Keras Model to TFLite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: assets/saved/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: assets/saved/assets\n",
      "2023-05-08 18:43:10.720295: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-05-08 18:43:10.720324: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-05-08 18:43:10.720437: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: assets/saved/\n",
      "2023-05-08 18:43:10.730569: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-05-08 18:43:10.730630: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: assets/saved/\n",
      "2023-05-08 18:43:11.325478: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2046] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
      "Details:\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x48xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x48xf32>>>, tensor<i32>, tensor<?x48xf32>) -> (tensor<!tf_type.variant<tensor<?x48xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<i32>, tensor<?x64xf32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x48xf32>>>, tensor<2xi32>) -> (tensor<1x?x48xf32>) : {device = \"\", num_elements = 1 : i64}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<2xi32>) -> (tensor<?x?x64xf32>) : {device = \"\", num_elements = -1 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_path = 'assets/model-backup.h5'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "model_path_alt = 'assets/saved/'\n",
    "tf.saved_model.save(model, model_path_alt)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(model_path_alt)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('assets/model_lstm2.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  }
 ],
 "kernelspec": {
  "display_name": "Python 3.8",
  "name": "py38"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d37fff4659cf8a883ce3d6c1246076e30e33dc297d4df960d23d9670e4eb60f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
