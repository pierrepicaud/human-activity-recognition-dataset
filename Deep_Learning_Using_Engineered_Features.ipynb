{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn sklearn keras_tuner lightgbm plotly &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store data\n",
    "# Logging\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# To get new datatypes and functions\n",
    "from cycler import cycler\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "# To create plots\n",
    "from matplotlib.colors import rgb2hex\n",
    "from numpy import pi\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# To create nicer plots\n",
    "import seaborn as sns\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# To build models\n",
    "from keras.models import Sequential\n",
    "from keras_tuner import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "# To gbm light\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# To create interactive plots\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "# To process data\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# To investigate distributions\n",
    "# from scipy.stats import norm, probplot, skew\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "init_notebook_mode(connected=True)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncompressing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./unzip.sh test.csv.zip train.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Combine boths dataframes\n",
    "train_data[\"Data\"] = \"Train\"\n",
    "test_data[\"Data\"] = \"Test\"\n",
    "both_data = pd.concat([train_data, test_data], axis=0).reset_index(drop=True)\n",
    "both_data[\"subject\"] = \"#\" + both_data[\"subject\"].astype(str)\n",
    "\n",
    "# Create label\n",
    "label = both_data.pop(\"Activity\")\n",
    "\n",
    "print(\"Shape Train:\\t{}\".format(train_data.shape))\n",
    "print(\"Shape Test:\\t{}\\n\".format(test_data.shape))\n",
    "\n",
    "train_data.head()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking categorical imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# dummy change\n",
    "fig = px.pie(train_data, names=\"Activity\", width=700)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        \"text\": \"Activities distribution in the data\",\n",
    "        \"y\": 0.95,\n",
    "        \"x\": 0.45,\n",
    "        \"xanchor\": \"center\",\n",
    "        \"yanchor\": \"top\",\n",
    "    }\n",
    ")\n",
    "fig.show()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting data\n",
    "label_counts = label.value_counts()\n",
    "\n",
    "# Get colors\n",
    "n = label_counts.shape[0]\n",
    "colormap = get_cmap(\"viridis\")\n",
    "colors = [rgb2hex(colormap(col)) for col in np.arange(0, 1.01, 1 / (n - 1))]\n",
    "\n",
    "# Create plot\n",
    "data = go.Bar(x=label_counts.index, y=label_counts, marker=dict(color=colors))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"Smartphone Activity Label Distribution\",\n",
    "    xaxis=dict(title=\"Activity\"),\n",
    "    yaxis=dict(title=\"Count\"),\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[data], layout=layout)\n",
    "iplot(fig)\n",
    ""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train And Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "x_train, y_train = train_data.iloc[:, :-2], train_data.iloc[:, -1:]\n",
    "x_test, y_test = test_data.iloc[:, :-2], test_data.iloc[:, -1:]\n",
    "x_train.shape, y_train.shape\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = test_data.iloc[:, :-2], test_data.iloc[:, -1:]\n",
    "x_test.shape, y_test.shape\n",
    ""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, y_test.shape, x_train.shape, y_train.shape\n",
    ""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    ""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    Dense(\n",
    "        units=64,\n",
    "        kernel_initializer=\"normal\",\n",
    "        activation=\"sigmoid\",\n",
    "        input_dim=x_train.shape[1],\n",
    "    )\n",
    ")\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=6, kernel_initializer=\"normal\", activation=\"softmax\"))\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test)\n",
    ")\n",
    "model.summary()\n",
    ""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int(\"num_layers\", 2, 25)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                units=hp.Int(\"units\" + str(i), min_value=32, max_value=512, step=32),\n",
    "                kernel_initializer=hp.Choice(\"initializer\", [\"uniform\", \"normal\"]),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"sigmoid\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            6,\n",
    "            kernel_initializer=hp.Choice(\"initializer\", [\"uniform\", \"normal\"]),\n",
    "            activation=\"softmax\",\n",
    "        )\n",
    "    )\n",
    "    model.add(Dropout(0.2))\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory=\"project\",\n",
    "    project_name=\"Human_activity_recognition\",\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "history = model.fit(x_train, y_train, epochs=51, validation_data=(x_test, y_test))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "Callback = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=3)\n",
    "mo_fitt = model.fit(\n",
    "    x_train, y_train, epochs=200, validation_data=(x_test, y_test), callbacks=Callback\n",
    ")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = mo_fitt.history[\"accuracy\"]\n",
    "loss = mo_fitt.history[\"loss\"]\n",
    "validation_loss = mo_fitt.history[\"val_loss\"]\n",
    "validation_accuracy = mo_fitt.history[\"val_accuracy\"]\n",
    "\n",
    "# dynamically set x based on y\n",
    "x = range(len(validation_loss))\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(x, accuracy, label=\"Training Accuracy\", color=\"blue\", linewidth=2)\n",
    "plt.plot(\n",
    "    x, validation_accuracy, label=\"Validation Accuracy\", color=\"green\", linewidth=2\n",
    ")\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.title(\"Accuracy: Training vs Validation\", fontsize=16)\n",
    "plt.xlabel(\"Epoch\", fontsize=14)\n",
    "plt.ylabel(\"Accuracy\", fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(x, loss, label=\"Training Loss\", color=\"blue\", linewidth=2)\n",
    "plt.plot(x, validation_loss, label=\"Validation Loss\", color=\"green\", linewidth=2)\n",
    "plt.legend(loc=\"upper right\", fontsize=14)\n",
    "plt.title(\"Loss: Training vs Validation\", fontsize=16)\n",
    "plt.xlabel(\"Epoch\", fontsize=14)\n",
    "plt.ylabel(\"Loss\", fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model(s) for development purposes\n",
    "import tensorflow as tf\n",
    "\n",
    "# create a TFLiteConverter object\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# convert the model to TFLite format\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# save the TFLite model to a file\n",
    "with open(\"./assets/model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d37fff4659cf8a883ce3d6c1246076e30e33dc297d4df960d23d9670e4eb60f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
